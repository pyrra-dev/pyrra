# Upstream Contribution Plan - Dynamic Burn Rate Feature

## Overview

This document outlines the plan for contributing the dynamic burn rate feature to the upstream Pyrra repository. The feature is complete and production-ready, with comprehensive testing and documentation already in place.

## Current Status

### âœ… Completed Work (Tasks 1-7)

All core development and validation is complete:

- **Backend Implementation**: Complete for all indicator types (ratio, latency, latencyNative, boolGauge)
- **UI Implementation**: Full UI integration with enhanced tooltips, traffic visualization, and error handling
- **Testing**: Comprehensive validation including:
  - Mathematical correctness (Task 7.2)
  - Query optimization (Task 7.10)
  - UI regression testing (Task 7.13 - zero regressions found)
  - Alert firing validation (Task 6)
  - Missing metrics handling
  - Performance benchmarking
- **Documentation**: Extensive internal documentation in `.dev-docs/` including:
  - Migration guides
  - Testing procedures
  - Implementation summaries
  - Troubleshooting guides
  - Performance benchmarks

### ðŸŽ¯ Remaining Work (Tasks 8-9)

Focus on upstream integration preparation:

**Task 8: Upstream Integration Preparation**
1. Fetch and merge from upstream
2. Organize files (PR vs fork)
3. Update production documentation
4. Create PR description

**Task 9: Final Validation**
1. Final regression verification
2. Code quality review
3. Production validation
4. Prepare for submission

## File Organization Strategy

### Files for Pull Request (Upstream)

**Core Implementation:**
- `slo/rules.go` - Dynamic burn rate backend logic
- `slo/slo.go` - Core types and interfaces
- `slo/promql.go` - PromQL query generation
- `kubernetes/api/v1alpha1/servicelevelobjective_types.go` - CRD with burnRateType field
- `ui/src/` - All UI components with dynamic burn rate support

**Essential Documentation:**
- `README.md` - Add dynamic burn rate feature section
- `examples/` - Add dynamic SLO examples
- Possibly new `docs/DYNAMIC_BURN_RATE.md` - User-facing feature documentation

**Minimal Tests:**
- Core unit tests in `slo/rules_test.go`
- Essential integration tests

### Files for Fork Only (Development Branch)

**Development Tools (`cmd/`):**
- `cmd/validate-ui-query-optimization/` - Query performance validation
- `cmd/test-burnrate-threshold-queries/` - Threshold calculation testing
- `cmd/test-query-aggregation/` - Query aggregation validation
- `cmd/validate-alert-rules/` - Alert rule validation
- `cmd/validate-recording-rules-*` - Recording rule validation tools
- `cmd/run-synthetic-test/` - Synthetic metric generation for testing
- `cmd/monitor-performance/` - Performance monitoring
- `cmd/generate-test-slos/` - Test SLO generation
- `cmd/test-health-check/` - Health check testing

**Development Documentation (`.dev-docs/`):**
- All 40+ development documents including:
  - Implementation summaries
  - Testing session notes
  - Validation reports
  - Troubleshooting guides
  - Performance benchmarks
  - Browser compatibility matrices

**Development Scripts (`scripts/`):**
- `scripts/validate_math_correctness.py`
- `scripts/test_scientific_notation.py`
- `scripts/validate-alert-rules.sh`
- `scripts/validate-recording-rules.sh`
- `scripts/production-readiness-test.sh`

**Test Configuration (`.dev/`):**
- All test SLO configurations
- Development environment setup files

**Project Management (`.kiro/`):**
- Steering documents
- Spec documents
- Hook configurations

**Prompts (`prompts/`):**
- All AI development session prompts

**Temporary Files:**
- All `.exe` files in root directory
- Build artifacts

## Upstream Merge Strategy

### Step 1: Fetch and Merge

```bash
# Add upstream remote (if not already added)
git remote add upstream https://github.com/pyrra-dev/pyrra.git

# Fetch latest upstream changes
git fetch upstream

# Merge upstream/main into feature branch
git merge upstream/main

# Resolve conflicts if any
# Test feature still works after merge
```

### Step 2: Create Development Branch

```bash
# Create branch to preserve all development artifacts
git checkout -b dev-tools-and-docs

# This branch stays in fork and contains:
# - All cmd/ tools
# - All .dev-docs/ documentation
# - All scripts/
# - All .dev/ test configs
# - All .kiro/ project files
# - All prompts/
```

### Step 3: Prepare PR Branch

```bash
# Switch back to feature branch
git checkout <feature-branch-name>

# Remove fork-only files (they're safe in dev-tools-and-docs branch)
# Clean up temporary files
# Update production documentation
```

## Documentation Update Strategy

### Production Documentation to Update

**IMPORTANT PRINCIPLE**: Keep updates minimal and proportional. Dynamic burn rate is ONE feature among many in Pyrra - don't overshadow existing content.

**README.md:**
- Add brief "Dynamic Burn Rate Alerting" section (2-3 paragraphs max)
- One-sentence explanation of traffic-aware thresholds
- Minimal configuration example (3-5 lines)
- Link to examples/ for more details

**examples/:**
- Add `examples/dynamic-burn-rate-ratio.yaml` (concise, well-commented)
- Add `examples/dynamic-burn-rate-latency.yaml` (concise, well-commented)
- Update `examples/README.md` with brief dynamic burn rate explanation (1-2 paragraphs)

**New Documentation (Optional):**
- Consider `docs/DYNAMIC_BURN_RATE.md` ONLY if it keeps main docs clean
- If created, keep it focused on practical usage, not implementation details
- Alternative: Integrate into existing documentation structure if it fits naturally

**Documentation Philosophy:**
- Focus on "what" and "how to use", not extensive "why" or implementation details
- Users should understand: feature exists, how to enable it, where to find examples
- Detailed information available in fork's `.dev-docs/` for those who need it

### Content to Extract from .dev-docs/

**For User-Facing Docs (Extract Minimally):**
- Brief feature overview from `FEATURE_IMPLEMENTATION_SUMMARY.md` (1-2 paragraphs)
- Simple migration guidance from `MIGRATION_GUIDE.md` (1-2 sentences)
- Key user-facing concepts from `CORE_CONCEPTS_AND_TERMINOLOGY.md` (avoid technical jargon)
- Usage examples from test configurations (simplify for production)

**Keep Internal (Don't Include in PR):**
- Detailed implementation notes
- Testing session documentation
- Validation reports
- Development workflow guides
- Performance benchmarking details
- Mathematical validation procedures

## Pull Request Description Template

### Title
```
feat: Add dynamic burn rate alerting for traffic-aware SLO thresholds
```

### Description

**Overview:**
Implements dynamic burn rate alerting that adapts alert thresholds based on actual traffic patterns, preventing false positives during low traffic and false negatives during high traffic periods.

**Motivation:**
Based on the "Error Budget is All You Need" blog series methodology. Static burn rate multipliers don't account for traffic variations, leading to alert sensitivity issues.

**Implementation:**
- Backend: Dynamic threshold calculation using `(N_SLO / N_alert) Ã— E_budget_percent Ã— (1 - SLO_target)` formula
- API: Added `burnRateType` field to SLO CRD and protobuf definitions
- UI: Enhanced threshold display, traffic visualization, and context-aware tooltips
- All indicator types supported: ratio, latency, latencyNative, boolGauge

**Testing:**
- Comprehensive mathematical validation (see validation tools in fork)
- Zero regressions in existing functionality
- Performance optimization (7x speedup for ratio indicators, 2x for latency)
- Alert firing validation with synthetic metrics
- UI regression testing across all indicator types

**Breaking Changes:**
None. Feature is opt-in via `burnRateType: dynamic` in SLO spec. Default behavior unchanged.

**Migration:**
Existing SLOs continue to work with static burn rates. To enable dynamic burn rates, add `burnRateType: dynamic` to SLO spec.

**Documentation:**
- Updated README.md with feature overview
- Added example configurations
- Detailed documentation available in fork

### Test Evidence Links

Include links to key validation results:
- Mathematical validation
- Performance benchmarks
- Regression testing results
- Alert firing validation

## Timeline

### Immediate (Task 8.1)
- Fetch and merge from upstream
- Resolve any conflicts
- Validate feature still works

### Short-term (Task 8.2-8.3)
- Create dev-tools-and-docs branch
- Organize files for PR vs fork
- Update production documentation

### Final (Task 8.4 + Task 9)
- Create PR description
- Final validation checks
- Code quality review
- Submit pull request

## Success Criteria

### Before PR Submission
- âœ… All conflicts with upstream resolved
- âœ… Feature works correctly after merge
- âœ… Development artifacts preserved in separate branch
- âœ… Production documentation updated
- âœ… PR description complete with evidence
- âœ… Code quality review passed
- âœ… Final validation checks passed

### PR Acceptance Criteria
- Feature provides clear value (traffic-aware alerting)
- No breaking changes to existing functionality
- Comprehensive testing evidence
- Clear documentation for users
- Code follows Pyrra conventions
- Backward compatible (opt-in feature)

## Notes

### Key Strengths
- **Production Ready**: Extensively tested with zero regressions
- **Backward Compatible**: Opt-in feature, existing SLOs unchanged
- **Well Documented**: Comprehensive internal documentation available
- **Performance Optimized**: Query optimization provides 2-7x speedup
- **All Indicator Types**: Complete support for ratio, latency, latencyNative, boolGauge

### Potential Questions from Reviewers
1. **Why dynamic burn rates?** - Addresses false positive/negative issues with static multipliers
2. **Performance impact?** - Actually improves performance through query optimization
3. **Complexity?** - Opt-in feature, doesn't affect existing users
4. **Testing?** - Comprehensive validation with multiple tools (available in fork)
5. **Maintenance?** - Clean implementation following existing patterns

### References
- "Error Budget is All You Need" blog series (methodology source)
- Comprehensive testing documentation in `.dev-docs/` (fork)
- Validation tools in `cmd/` (fork)
- Task 7.13 regression testing results (zero regressions)

## Contact

For questions about implementation details, testing methodology, or validation results, refer to the comprehensive documentation in the fork's `.dev-docs/` directory.
